{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/begood/Videos/billiejean.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frames_dir = \"./frames\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!rm -rf $frames_dir results\n",
    "!mkdir $frames_dir\n",
    "!ffmpeg -i $filename -vf fps=24 $frames_dir/out%d.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import FastDVDnet\n",
    "from fastdvdnet import denoise_seq_fastdvdnet\n",
    "from utils import batch_psnr, init_logger_test, \\\n",
    "            variable_to_cv2_image, remove_dataparallel_wrapper, open_sequence, close_logger, get_imagenames\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "args['save_path'] = \"results\"\n",
    "args['noise_sigma'] = 5 / 255\n",
    "args['max_num_fr_per_seq'] = 5\n",
    "#args['model_spatial_file'] = \"model_spatial.pth\"\n",
    "model = \"./model.pth\"\n",
    "args['suffix'] = \"\"\n",
    "save_noisy = False\n",
    "save_results = True\n",
    "args['gray'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['cuda'] = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IN_FR_EXT = 5 # temporal size of patch\n",
    "#MC_ALGO = 'DeepFlow' # motion estimation algorithm\n",
    "OUTIMGEXT = '.png' # output images format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If save_path does not exist, create it\n",
    "if not os.path.exists(args['save_path']):\n",
    "    os.makedirs(args['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets data type according to CPU or GPU modes\n",
    "if args['cuda']:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "model_temp = FastDVDnet(num_input_frames=NUM_IN_FR_EXT)\n",
    "state_temp_dict = torch.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_temp_dict = torch.load(model)\n",
    "if args['cuda']:\n",
    "    device_ids = [0]\n",
    "    model_temp = nn.DataParallel(model_temp, device_ids=device_ids).cuda()\n",
    "else:\n",
    "    # CPU mode: remove the DataParallel wrapper\n",
    "    state_temp_dict = remove_dataparallel_wrapper(state_temp_dict)\n",
    "model_temp.load_state_dict(state_temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval mode set\n"
     ]
    }
   ],
   "source": [
    "model_temp.eval()\n",
    "print(\"Eval mode set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_file = len(os.listdir(frames_dir))\n",
    "# Get ordered list of filenames\n",
    "#files = get_imagenames(frames_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def save_out_seq(seqclean, save_dir, sigmaval, start_idx):\n",
    "    \"\"\"Saves the denoised and noisy sequences under save_dir\n",
    "    \"\"\"\n",
    "    seq_len = seqclean.size()[0]\n",
    "    for idx in range(seq_len):\n",
    "        save_img(seqclean, save_dir, sigmaval, start_idx,idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def save_img(seq, save_dir, sigmaval, start_idx, idx):\n",
    "    out_name = os.path.join(save_dir,\\\n",
    "                ('n{}_DVDnet_{:0>15}').format(sigmaval, start_idx+idx) + OUTIMGEXT)\n",
    "\n",
    "    outimg = variable_to_cv2_image(seq[idx].unsqueeze(dim=0))\n",
    "    cv2.imwrite(out_name, outimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i= 0\n",
    "while video.isOpened():\n",
    "video.set(1, 1500)\n",
    "ret, frame = video.read()\n",
    "#gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Display the resulting frame\n",
    "plt.imshow(frame)\n",
    "plt.show()\n",
    "#if i > 50:\n",
    "#    break\n",
    "#i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of frames to process: 8866\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(filename)\n",
    "nb_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Amount of frames to process: {}\".format(nb_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second: 29.97002997002997\n"
     ]
    }
   ],
   "source": [
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "width  = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc('P','I','M','1')\n",
    "out_filename = \"{}-NONOISE2-DENOISED-noise{}-batch{}.mkv\".format(filename,int(args['noise_sigma']*255),args['max_num_fr_per_seq'])\n",
    "print(\"Frames per second: {}\".format(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1773/1774 [09:40<00:00,  3.05it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8519a0fdabb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                         \u001b[0mnoise_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoisestd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                         \u001b[0mtemp_psz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_IN_FR_EXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                         model_temporal=model_temp)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/fastdvdnet/fastdvdnet.py\u001b[0m in \u001b[0;36mdenoise_seq_fastdvdnet\u001b[0;34m(seq, noise_std, temp_psz, model_temporal)\u001b[0m\n\u001b[1;32m     59\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_psz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                                 \u001b[0mrelidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mctrlfr_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# handle border conditions, reflect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                 \u001b[0minframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                         \u001b[0;32mdel\u001b[0m \u001b[0minframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "out = cv2.VideoWriter(out_filename, fourcc, fps, (width,height))\n",
    "batch = args['max_num_fr_per_seq']\n",
    "for fidx in trange(0, nb_frames, batch):\n",
    "    \n",
    "    max_num_fr=batch\n",
    "    if fidx+batch > nb_frames:\n",
    "        max_num_fr = nb_frames-fidx\n",
    "        \n",
    "    #print(\"Processing sequences from {} to {}\".format(fidx, fidx+max_num_fr))\n",
    "    seq, _, _ = open_sequence(video,\\\n",
    "                    args['gray'],\\\n",
    "                    expand_if_needed=False,\\\n",
    "                    start_index=fidx, max_num_fr=max_num_fr)\n",
    "    # process data\n",
    "    with torch.no_grad():\n",
    "        seq = torch.from_numpy(seq).to(device)\n",
    "\n",
    "        # Add noise\n",
    "        noise = torch.empty_like(seq).normal_(mean=0, std=args['noise_sigma']).to(device)\n",
    "        seqn = seq #+ noise\n",
    "        noisestd = torch.FloatTensor([args['noise_sigma']]).to(device)\n",
    "        #print(\"Denoising...\")\n",
    "\n",
    "        denframes = denoise_seq_fastdvdnet(seq=seqn,\\\n",
    "                                        noise_std=noisestd,\\\n",
    "                                        temp_psz=NUM_IN_FR_EXT,\\\n",
    "                                        model_temporal=model_temp)\n",
    "    \n",
    "    for idx in range(len(denframes)):\n",
    "        outimg = variable_to_cv2_image(denframes[idx].unsqueeze(dim=0))\n",
    "        out.write(outimg)\n",
    "        \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "#save_out_seq(denframes, args['save_path'], int(noise_sigma*255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ffmpeg -framerate 24 \\\n",
    "    -pattern_type glob \\\n",
    "    -i 'results/*.png' \\\n",
    "    -c:v libx264  \\\n",
    "    -r 30 \\\n",
    "    -pix_fmt yuv420p10le \\\n",
    "    -map_chapters 0 \\\n",
    "    -preset fast \\\n",
    "    -crf 21 \\\n",
    "    -c:a copy \\\n",
    "    out.mkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, _, _ = open_sequence(video,\\\n",
    "                args['gray'],\\\n",
    "                expand_if_needed=False,\\\n",
    "                start_index=fidx, max_num_fr=max_num_fr)\n",
    "# process data\n",
    "with torch.no_grad():\n",
    "    seq = torch.from_numpy(seq).to(device)\n",
    "\n",
    "    # Add noise\n",
    "    noise = torch.empty_like(seq).normal_(mean=0, std=args['noise_sigma']).to(device)\n",
    "    seqn = seq #+ noise\n",
    "    noisestd = torch.FloatTensor([args['noise_sigma']]).to(device)\n",
    "    #print(\"Denoising...\")\n",
    "\n",
    "    denframes = denoise_seq_fastdvdnet(seq=seqn,\\\n",
    "                                    noise_std=noisestd,\\\n",
    "                                    temp_psz=NUM_IN_FR_EXT,\\\n",
    "                                    model_temporal=model_temp)\n",
    "\n",
    "for idx in range(len(denframes)):\n",
    "    outimg = variable_to_cv2_image(denframes[idx].unsqueeze(dim=0))\n",
    "    out.write(outimg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
